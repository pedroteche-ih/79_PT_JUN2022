{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "sns.set_theme(context = 'notebook', style = 'darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de Classificação II\n",
    "\n",
    "Vamos avançar nossos estudos sobre métodos de classificação analisando dois novos algoritmos (o *Perceptron de Múltiplas Camadas* e os *Modelos de Ensemble*). Além disso teremos o primeiro contato com os conceitos de *underfitting* e *overfitting*, e como esses conceitos se relacionam com a **complexidade** dos modelos de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_hotel_train = pd.read_csv(\"data/tb_hotel_train_clean.csv\")\n",
    "tb_hotel_test = pd.read_csv(\"data/tb_hotel_test_clean.csv\")\n",
    "tb_hotel_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = [\"lead_time\", \"adr\"]\n",
    "X_train = tb_hotel_train[x_var]\n",
    "X_test = tb_hotel_test[x_var]\n",
    "y_train = tb_hotel_train[\"is_cancelled\"]\n",
    "y_test = tb_hotel_test[\"is_cancelled\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar a visualização dos nossos modelos continuaremos nos restringindo à duas variáveis: `lead_time` e `adr`. Vamos criar dois DataFrames para visualizar separadamente os efeitos de cada variável sobre **a função de probabilidade** estimada por cada algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time_simul = list(np.linspace(-1, 3, 100)) * 3\n",
    "adr_simul = [-1] * 100 + [0] * 100 + [1] * 100\n",
    "tb_simul_lt = pd.DataFrame({'lead_time' : lead_time_simul, 'adr' : adr_simul})\n",
    "tb_simul_lt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_simul = list(np.linspace(-2, 2, 100)) * 3\n",
    "lead_time_simul = [-1] * 100 + [0] * 100 + [1] * 100\n",
    "tb_simul_adr = pd.DataFrame({'lead_time' : lead_time_simul, 'adr' : adr_simul})\n",
    "tb_simul_adr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um DataFrame com os dados originais de teste para guardarmos as diferentes previsões de nossos modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_fits = X_test.copy()\n",
    "tb_fits[\"is_cancelled\"] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais\n",
    "\n",
    "Redes neurais são uma classe de modelo preditivo que surgiu a partir da pesquisa sobre o funcionamento das células neuronais do cérebro - desenvolvida inicialmente por McCulloh e Pitts na década de 40. O modelo mais comum de rede neural, o **perceptron de múltiplas camadas (MLP)** foi desenvolvido em 1958 pelo psicológo Rosenblatt.\n",
    "\n",
    "Os **MLPs** são caracterizados por dois atributos fundamentais:\n",
    "\n",
    "* Número de neurônios por camada;\n",
    "* Função de Ativação.\n",
    "\n",
    "![MLP](images/multipercep.jpg)\n",
    "\n",
    "Vamos criar um MLP para resolver nosso problema de classificação, variando o tamanho de nossa rede neural e analisando o resultado de nossas previsões:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_fit = MLPClassifier(hidden_layer_sizes=(4, 4), activation = 'relu', max_iter=1000)\n",
    "nn_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_fits[\"pred_prob_nn\"] = nn_fit.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "sns.scatterplot(\n",
    "    data=tb_fits, \n",
    "    x=\"lead_time\", y=\"pred_prob_nn\", hue = \"adr\", \n",
    "    ax =ax[0], palette='Spectral')\n",
    "sns.scatterplot(\n",
    "    data=tb_fits, \n",
    "    x=\"adr\", y=\"pred_prob_nn\", hue = \"lead_time\", \n",
    "    ax = ax[1], palette = 'Spectral');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar a não-linearidade das redes neurais através das superficies de decisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plot_decision_regions(\n",
    "    np.array(tb_fits[[\"lead_time\", \"adr\"]]),\n",
    "    np.array(tb_fits[\"is_cancelled\"]),\n",
    "    nn_fit,\n",
    "    scatter_kwargs={\"alpha\": 0.001},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_simul_lt['pred_prob_nn1'] = nn_fit.predict_proba(tb_simul_lt[x_var])[:,1]\n",
    "tb_simul_adr['pred_prob_nn1'] = nn_fit.predict_proba(tb_simul_adr[x_var])[:,1]\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "sns.lineplot(\n",
    "    data=tb_simul_lt, \n",
    "    x=\"lead_time\", y=\"pred_prob_nn1\", hue = \"adr\", \n",
    "    ax =ax[0], palette='Spectral')\n",
    "sns.lineplot(\n",
    "    data=tb_simul_adr, \n",
    "    x=\"adr\", y=\"pred_prob_nn1\", hue = \"lead_time\", \n",
    "    ax = ax[1], palette = 'Spectral');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma nova rede neural como a mesma função de ativação (`relu`) mas aumentando o número de neurônios por camada e o número de camadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_fit_2 = MLPClassifier(hidden_layer_sizes=(20,20,20), activation = 'relu')\n",
    "nn_fit_2.fit(X_train, y_train)\n",
    "\n",
    "tb_fits[\"pred_prob_nn2\"] = nn_fit_2.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "sns.scatterplot(\n",
    "    data=tb_fits, \n",
    "    x=\"lead_time\", y=\"pred_prob_nn2\", hue = \"adr\", \n",
    "    ax =ax[0], palette='Spectral')\n",
    "sns.scatterplot(\n",
    "    data=tb_fits, \n",
    "    x=\"adr\", y=\"pred_prob_nn2\", hue = \"lead_time\", \n",
    "    ax = ax[1], palette = 'Spectral');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já podemos ver que os padrões encontrados pela nossa rede neural se tornaram mais complexos: podemos visualizar isso de forma mais direta através da superficie de decisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plot_decision_regions(\n",
    "    np.array(tb_fits[[\"lead_time\", \"adr\"]]),\n",
    "    np.array(tb_fits[\"is_cancelled\"]),\n",
    "    nn_fit_2,\n",
    "    scatter_kwargs={\"alpha\": 0.001},\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto mais irregulares a separação entre as duas classes, mais complexo é o modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_simul_lt['pred_prob_nn2'] = nn_fit_2.predict_proba(tb_simul_lt[x_var])[:,1]\n",
    "tb_simul_adr['pred_prob_nn2'] = nn_fit_2.predict_proba(tb_simul_adr[x_var])[:,1]\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "sns.lineplot(\n",
    "    data=tb_simul_lt, \n",
    "    x=\"lead_time\", y=\"pred_prob_nn2\", hue = \"adr\", \n",
    "    ax =ax[0], palette='Spectral')\n",
    "sns.lineplot(\n",
    "    data=tb_simul_adr, \n",
    "    x=\"adr\", y=\"pred_prob_nn2\", hue = \"lead_time\", \n",
    "    ax = ax[1], palette = 'Spectral');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, os efeitos das duas variáveis de nosso modelo são mais irregulares na segunda rede neural. A capacidade de representar superficies de decisão complexas é uma das grandes vantagens que os algoritmos de ML tem sobre métodos mais tradicionais como a regressão logística. No entanto, a complexidade introduz um novo problema: overfitting.\n",
    "\n",
    "# Complexidade e Overfitting\n",
    "\n",
    "Para avaliarmos melhor a relação entre complexidade e overfitting, vamos carregar mais variáveis de nosso dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_of = pd.read_csv('data/tb_hotel_train_overfit.csv')\n",
    "test_of = pd.read_csv('data/tb_hotel_test_overfit.csv')\n",
    "\n",
    "X_train_of = train_of.drop('is_cancelled', axis = 1)\n",
    "X_test_of = test_of.drop('is_cancelled', axis = 1)\n",
    "y_train_of = train_of['is_cancelled']\n",
    "y_test_of = test_of['is_cancelled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos no começo do Módulo III, podemos dividir a utilização dos algoritmos de ML em duas etapas:\n",
    "\n",
    "* **Aprendizagem**, onde o algoritmo *aprende* as relações entre nossas *features* e a *variável resposta* utilizando dados históricos (representados pelo conjunto de treinamento);\n",
    "* **Predição**, onde utilizamos os padrões *aprendidos* pelo algoritmo para realizar projeções sobre novos dados a partir de nossos *features* (represetado pelo conjunto de teste).\n",
    "\n",
    "A **fase de aprendizagem** consiste na otimização do erro de projeção sobre o conjunto de treinamento - o modelo ajusta gradualmente seus coeficientes buscando melhorar a cada etapa seu erro de projeção sobre os dados históricos. Conforme aumentamos a **complexidade** do modelo essa otimização torna-se cada vez mais eficiente. \n",
    "\n",
    "Isso não significa, necessariamente, que o erro de previsão do modelo melhorará! Conforme a **complexidade** aumenta, o modelo perde a **capacidade de generalização**: ao invés de *encontrar padrões* nos dados históricos ele aprende regras que se aplicam somente às observações do conjunto de treinamento.\n",
    "\n",
    "Vamos utilizar uma árvore de decisão para visualizar este processo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As árvores de decisão tem um parâmetro de complexidade muito simples, a **profundida máxima**. Vamos utilizar um `loop for` para construir árvores de decisão de diferentes profundidades e avaliar seu erro sobre o conjunto de treinamento e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(2, 40, 20)]\n",
    "\n",
    "d_list = []\n",
    "f1_train_list = []\n",
    "f1_test_list = []\n",
    "\n",
    "for d in max_depth:\n",
    "    rf_fit = DecisionTreeClassifier(max_depth= d)\n",
    "    rf_fit.fit(X_train_of, y_train_of)\n",
    "    y_pred_test = rf_fit.predict(X_test_of)\n",
    "    y_pred_train = rf_fit.predict(X_train_of)\n",
    "\n",
    "    f1_test = np.round(f1_score(y_test_of, y_pred_test), 4)\n",
    "    f1_train = np.round(f1_score(y_train_of, y_pred_train), 4)\n",
    "\n",
    "\n",
    "    d_list.append(d)\n",
    "    f1_train_list.append(f1_train)\n",
    "    f1_test_list.append(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_rf_fit = pd.DataFrame(\n",
    "    {\n",
    "        'depth' : d_list,\n",
    "        'f1_train' : f1_train_list,\n",
    "        'f1_test' : f1_test_list\n",
    "    }\n",
    ")\n",
    "tb_rf_fit['diff_error'] = tb_rf_fit['f1_train'] - tb_rf_fit['f1_test']\n",
    "tb_rf_fit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos comparar a evolução do erro sobre os dois conjuntos, teste e treinamento, para visualizar o impacto da complexidade (representada pela profundidade) sobre underfitting/overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = tb_rf_fit, x = 'depth', y = 'f1_train')\n",
    "sns.lineplot(data = tb_rf_fit, x = 'depth', y = 'f1_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de Ensemble\n",
    "\n",
    "Como vimos no exemplo acima, conforme o número de *features* em nosso dataset cresce, árvores de decisão tornam-se extremamente sensíveis à *overfitting*. Para contornar este problema, foram desenvolvidos os **métodos de ensemble**: ao invés de utilizar uma árvore de decisão complexa para realizazr previsões, podemos utilizar muitas árvores simples, reduzindo a chance que qualquer árvore em particular cause overfitting. Veremos hoje as duas principais **estratégias** de *ensemble*: **bagging** e **boosting**.\n",
    "\n",
    "## Bagging\n",
    "\n",
    "Os métodos de *bagging* constroem árvores *em paralelo*: ao invés de criar uma árvore complexa, vamos criar muitas árvores de decisão de profundidade limitada (chamadas de *weak learners*). Além de limitar a profundidade máxima de cada *weak learner* vamos treiná-los sobre **amostras do nosso conjunto de treinamento**, ou seja, cada *weak learner* verá uma parte diferente de nosso dataset, garantindo que nenhum deles sofra com **overfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fit = RandomForestClassifier(n_estimators = 1500, max_depth= 3)\n",
    "rf_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_fits[\"pred_prob_rf\"] = rf_fit.predict_proba(X_test)[:, 1]\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "sns.scatterplot(\n",
    "    data=tb_fits, \n",
    "    x=\"lead_time\", y=\"pred_prob_rf\", hue = \"adr\", \n",
    "    ax =ax[0], palette='Spectral')\n",
    "sns.scatterplot(\n",
    "    data=tb_fits, \n",
    "    x=\"adr\", y=\"pred_prob_rf\", hue = \"lead_time\", \n",
    "    ax = ax[1], palette = 'Spectral');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plot_decision_regions(\n",
    "    np.array(tb_fits[[\"lead_time\", \"adr\"]]),\n",
    "    np.array(tb_fits[\"is_cancelled\"]),\n",
    "    rf_fit,\n",
    "    scatter_kwargs={\"alpha\": 0.001},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_simul_lt['pred_prob_rf'] = rf_fit.predict_proba(tb_simul_lt[x_var])[:,1]\n",
    "tb_simul_adr['pred_prob_rf'] = rf_fit.predict_proba(tb_simul_adr[x_var])[:,1]\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "sns.lineplot(\n",
    "    data=tb_simul_lt, \n",
    "    x=\"lead_time\", y=\"pred_prob_rf\", hue = \"adr\", \n",
    "    ax =ax[0], palette='Spectral')\n",
    "sns.lineplot(\n",
    "    data=tb_simul_adr, \n",
    "    x=\"adr\", y=\"pred_prob_rf\", hue = \"lead_time\", \n",
    "    ax = ax[1], palette = 'Spectral');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Enquanto *bagging* utiliza *weak learners* em paralelo, a estratégia de **boosting** os utiliza em série: cada árvore subsequente em nosso modelo é criada para **prever** os erros do *weak learner* anterior!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_fit = CatBoostClassifier(\n",
    "    iterations = 500, depth=4\n",
    "    )\n",
    "cat_fit.fit(X_train, y_train, eval_set = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_fits[\"pred_prob_cat\"] = cat_fit.predict_proba(X_test)[:, 1]\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "sns.scatterplot(\n",
    "    data=tb_fits, \n",
    "    x=\"lead_time\", y=\"pred_prob_cat\", hue = \"adr\", \n",
    "    ax =ax[0], palette='Spectral')\n",
    "sns.scatterplot(\n",
    "    data=tb_fits, \n",
    "    x=\"adr\", y=\"pred_prob_cat\", hue = \"lead_time\", \n",
    "    ax = ax[1], palette = 'Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plot_decision_regions(\n",
    "    np.array(tb_fits[[\"lead_time\", \"adr\"]]),\n",
    "    np.array(tb_fits[\"is_cancelled\"]),\n",
    "    cat_fit,\n",
    "    scatter_kwargs={\"alpha\": 0.001},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_simul_lt['pred_prob_cat'] = cat_fit.predict_proba(tb_simul_lt[x_var])[:,1]\n",
    "tb_simul_adr['pred_prob_cat'] = cat_fit.predict_proba(tb_simul_adr[x_var])[:,1]\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "sns.lineplot(\n",
    "    data=tb_simul_lt, \n",
    "    x=\"lead_time\", y=\"pred_prob_cat\", hue = \"adr\", \n",
    "    ax =ax[0], palette='Spectral')\n",
    "sns.lineplot(\n",
    "    data=tb_simul_adr, \n",
    "    x=\"adr\", y=\"pred_prob_cat\", hue = \"lead_time\", \n",
    "    ax = ax[1], palette = 'Spectral');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "014f4a4a5af8f0104b12c029e500f4146d6d785e8cf714d2a35b7a9514230cd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
