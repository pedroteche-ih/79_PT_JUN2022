{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Workflow\n",
    "\n",
    "A construção dos modelos de Machine Learning muitas vezes depende mais da qualidade dos dados e dos cuidados tomados contra **data leakage** do que das escolhas técnicas do cientista de dados. Hoje veremos um *workflow* padrão para a trabalhar com conjuntos de dados - garantindo que não exista leakage e que nosso conjunto de treinamento está limpo.\n",
    "\n",
    "Além disso, devemos sempre lembrar que os modelos preditivos **existem para fazer previsões**! Um dos maiores problemas hoje em dia no campo de machine learning é a dificuldade em levar um modelo da fase de protótipo à produção. Vamos discutir ao longo da aula pontos sensíveis na implantação de um modelo e que como podemos evitar armadilhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_hotel = pd.read_csv(\"data/tb_hotel_aula.csv\")\n",
    "tb_hotel.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evitando *leakage*\n",
    "\n",
    "*Data leakage* é um erro extremamente comum no campo de ciência de dados. Em uma análise feita para um [artigo da revista Nature](https://www.nature.com/articles/d41586-022-02035-w), em um review de 340 artigos, 329 apresentavam **falhas em reprodutibilidade**. Outro estudo, conduzido na Universidade de Birmingham, apontou que menos de 5% dos artigos médicos utilizando Machine Learning se preocupavam com a possibilidade de implantação dos modelos em ambiente clínicos.\n",
    "\n",
    "*Leakage* acontece quando não garantimos, na etapa de construção do modelo, que estamos operando dentro das mesmas condições que o modelo irá operar quando estiver em produção. Para garantir estas condições precisamos cumprir duas etapas:\n",
    "\n",
    "1. **Limpeza de variáveis**: como conjuntos de dados utilizados na construção de modelos são sempre dados históricos, precisamos garantir que as variáveis que estamos utilizando estarão disponíveis do momento em que o modelo for utilizado para fazer previsões;\n",
    "1. **Avaliação de Erro em conjunto Teste**: para modelos preditivos, precisamos avaliar o erro de previsão destes modelos em conjuntos de dados que não foram utilizados nas etapas de aprendizagem.\n",
    "\n",
    "Na primeira etapa **precisamos descobrir e entender como o dado é produzido**: quais sistemas são utilizados, quais são os *fatos transacionais*, e, finalmente, quais as informações que estarão disponíveis no momento de predição. Além disso, precisamos **garantir** que as etapas de pré-processamento do modelo **funcionarão** sobre dados futuros!\n",
    "\n",
    "Excluindo variáveis que não estarão disponíveis em sua forma histórica em dados presentes, a divisão test/train possibilita que avaliemos o modelo em todas as suas etapas: pré-processamento, aprendizagem e avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var = [\"lead_time\", \"country\", \"company\", \"children\", \"adults\", \"meal\"]\n",
    "y_var = \"is_cancelled\"\n",
    "X = tb_hotel[X_var]\n",
    "y = tb_hotel[y_var]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratando NAs\n",
    "\n",
    "Para tratar de valores NA em um modelo de machine learning, não basta *exluir linhas*! Temos que lembrar que, em produção, os dados alimentados ao modelo poderão conter NAs. Precisamos criar mecânismos que **preencham** esses valores ou então desncosiderar as variáveis que podem conte-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum() / X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratativas Manuais\n",
    "\n",
    "A melhor forma de tratar valores NA é compreendendo **porque eles existem** em uma dada variável. Se conhecemos as causas por trás destes valores, podemos criar tratativas diretas e específicas à cada variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_na_company = X_train[\"company\"].isna()\n",
    "\n",
    "X_train.loc[mask_na_company, \"is_company\"] = 0\n",
    "X_train.loc[~mask_na_company, \"is_company\"] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputando valores\n",
    "\n",
    "Caso não seja possível elucidar porque certas variáveis contém NAs, podemos recorrer a **imputação de valores**. A imputação pode ser arriscada se os valores não foram gerados por erros de sistema, ou então se tem uma estrutura subjacente, portanto devemos utiliza-la apenas após estudar o processo de geração de dados e garantir que estes valores são:\n",
    "\n",
    "1. Raros;\n",
    "1. Causados por falhas no sistema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "country_imputer.fit(X_train[[\"country\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children_imputer = SimpleImputer(strategy=\"median\")\n",
    "children_imputer.fit(X_train[[\"children\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"country_imp\"] = country_imputer.transform(X_train[[\"country\"]])\n",
    "X_train[\"children_imp\"] = children_imputer.transform(X_train[[\"children\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train[\"country\"].isna(), [\"country\", \"country_imp\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train[\"children\"].isna(), [\"children\", \"children_imp\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo colunas\n",
    "\n",
    "Caso uma coluna não tenha uma trativa direta e contém valores NA demais para imputação, devemos desconsiderar esta variável no nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\"company\", \"country\", \"children\"], axis=1)\n",
    "X_train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lidando com Variáveis Categóricas\n",
    "\n",
    "As variáveis categóricas apresentam algumas dificuldades quando utilizadas em modelos:\n",
    "\n",
    "1. No caso de One-Hot encoding, devemos garantir que nosso programa **saiba lidar com níveis novos da variável**;\n",
    "1. Além disso, precisamos garantir que não criemos variáveis dummies para níveis com poucas observações (níveis raros).\n",
    "\n",
    "No caso de utilizarmos variáveis **Ordinais**, precisamos garantir que a **codificação** destas variáveis faça sentido!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.select_dtypes(exclude=\"number\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [\"country_imp\"]\n",
    "ord_vars = [\"meal\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando níveis raros\n",
    "\n",
    "A forma mais comum de tratar níveis raros é agrupando-os em uma nova categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_niveis_country = (\n",
    "    X_train[cat_vars].value_counts().reset_index().rename({0: \"num_obs\"}, axis=1)\n",
    ")\n",
    "tb_niveis_country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_niveis = tb_niveis_country[\"num_obs\"] > (sum(tb_niveis_country[\"num_obs\"]) * 0.01)\n",
    "tb_niveis_country.loc[mask_niveis, \"country_grp\"] = tb_niveis_country[\"country_imp\"]\n",
    "tb_niveis_country.loc[~mask_niveis, \"country_grp\"] = \"Others\"\n",
    "tb_niveis_country.index = tb_niveis_country[\"country_imp\"]\n",
    "tb_niveis_country = tb_niveis_country.drop([\"num_obs\", \"country_imp\"], axis=1)\n",
    "tb_niveis_country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_country = tb_niveis_country.to_dict()[\"country_grp\"]\n",
    "X_train[\"country_grp\"] = X_train[\"country_imp\"].map(dict_country)\n",
    "X_train = X_train.drop(\"country_imp\", axis=1)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "Após tratarmos níveis raros, podemos utilizar o `OneHotEncoder` para criar nossa variáveis dummies de forma robusta, garantindo que novos níveis em dados futuros (ou no conjunto de teste) não causarão erros em nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_vars = [\"country_grp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, drop=\"first\", handle_unknown=\"ignore\")\n",
    "ohe.fit(X_train[ohe_vars])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(X_train[ohe_vars])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_dummies_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[ohe_vars]), columns=ohe.get_feature_names_out(), index = X_train.index\n",
    ")\n",
    "tb_dummies_cat.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis Ordinais\n",
    "\n",
    "Além do One-Hot Encoding, podemos converter nossas categorias em variáveis numéricas (se elas possuem um ordenamento natural). Vamos utilizar o `OrdinalEncoder` para tratar a variável `meal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"meal\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal = OrdinalEncoder(categories=[[\"Undefined\", \"SC\", \"BB\", \"HB\", \"FB\"]])\n",
    "ordinal.fit(X_train[[\"meal\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"num_meal\"] = ordinal.transform(X_train[[\"meal\"]])\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando Outliers\n",
    "\n",
    "Valores extremos em variáveis numéricas são como níveis raros em variáveis categóricas. Muitas vezes, estes valores podem impactar o resultado de um modelo, mesmo tendo um pequeno volume de observações. No entanto, devemos nos lembrar que o filtro de outliers **só pode ser feito no conjunto de treinamento!** \n",
    "\n",
    "Afinal, essas observações fazem parte do processo de geração dos dados - nosso modelo precisará fazer previsões para esses valores. Remove-los do conjunto de treinamento garante que nosso modelo *não aprenda pela exceção!*\n",
    "\n",
    "Vamos aprender algumas formas diferentes de limpar outliers, entendendo suas forças e fragilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=X_train, y=\"lead_time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regra n-Sigma: 68-95-99\n",
    "\n",
    "A regra 68-95-99 de limpeza é calcada na forma da distribuição normal: 99% dos dados estão a menos de 3 desvios padrões da média. Muitas vezes, filtramos outliers utilizando o intervalo de 2-sigmas, descartando 5% das observações com valores mais extremos.\n",
    "\n",
    "A regra `n-Sigma` é ótima se nossa variável é **simétrica**, ou seja, se a variação para cima da média é semelhante a variação para baixo da média. Caso contrário, podemos descartar muitos dados em um eixo só: por exemplo removendo estes 5% só da parte superior da distribuição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_lead_time = X_train[\"lead_time\"].mean()\n",
    "sig_lead_time = X_train[\"lead_time\"].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_95 = (X_train[\"lead_time\"] > (mu_lead_time - 2 * sig_lead_time)) & (\n",
    "    X_train[\"lead_time\"] < (mu_lead_time + 2 * sig_lead_time)\n",
    ")\n",
    "print(mask_95.sum() / X_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[mask_95, \"out_2sig\"] = \"Inlier 2-Sigma\"\n",
    "X_train.loc[~mask_95, \"out_2sig\"] = \"Outlier 2-Sigma\"\n",
    "sns.boxplot(data=X_train, x=\"out_2sig\", y=\"lead_time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual o problema com a exclusão acima?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desigualdade de Chebyshev\n",
    "\n",
    "A desigualdade de Chebyshev é uma extensão da regra n-Sigma para **qualquer distribuição comum (simétrica ou assimétrica)**: ela nos garante que 96% dos dados estarão à 5 desvios padrões da média.\n",
    "\n",
    "Essa estimativa é extremamente conservadora - o que faz com que exclusão de outliers seja suave. Esta é uma regra **que sempre podemos aplicar sobre variáveis numéricas!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_cheby = (X_train[\"lead_time\"] > (mu_lead_time - 5 * sig_lead_time)) & (\n",
    "    X_train[\"lead_time\"] < (mu_lead_time + 5 * sig_lead_time)\n",
    ")\n",
    "print(mask_cheby.sum() / X_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[mask_cheby, \"out_cheby\"] = \"Inlier Chebyshev\"\n",
    "X_train.loc[~mask_cheby, \"out_cheby\"] = \"Outlier Chebyshev\"\n",
    "sns.boxplot(data=X_train, x=\"out_cheby\", y=\"lead_time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando a IQR\n",
    "\n",
    "Podemos utilizar a distância interquartil para estimar thresholds de outliers assimétricos. A regra IQR funciona como um meio termo robusto entre a desigualdade de Chebyshev e a regra n-Sigma.\n",
    "\n",
    "Como esta regra utiliza os *quantis* de uma variável, devemos tomar cuidado com variáveis extremamente concentradas (algo comum em variáveis de contagem por exemplo): nesses cassos muitas vezes o terceiro quartil é igual ao primeiro quartil - levando à uma exclusão de toda variação presente na variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q25 = np.quantile(X_train[\"lead_time\"], 0.25)\n",
    "q75 = np.quantile(X_train[\"lead_time\"], 0.75)\n",
    "iqr = q75 - q25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_iqr = (X_train[\"lead_time\"] > (q25 - 1.5 * iqr)) & (\n",
    "    X_train[\"lead_time\"] < (q75 + 1.5 * iqr)\n",
    ")\n",
    "print(mask_iqr.sum() / X_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[mask_iqr, \"out_iqr\"] = \"Inlier IQR\"\n",
    "X_train.loc[~mask_iqr, \"out_iqr\"] = \"Outlier IQR\"\n",
    "sns.boxplot(data=X_train, x=\"out_iqr\", y=\"lead_time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando normalizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_var = ['lead_time', 'adults', 'children_imp', 'num_meal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[num_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo nossos conjuntos de treinamento e teste\n",
    "\n",
    "1. Podemos alterar o número de linhas **APENAS** no **conjunto de treinamento**;\n",
    "    * *Isso inclui qualquer operação de limpeza de NAs e outliers.*\n",
    "1. Qualquer etapa de **aprendizagem** pode ser executada apenas no **conjunto de treinamento**;\n",
    "    * *Isso inclui encoders (ordinais e OH), imputadores, normalizadores e agrupamento de valores categóricos.*\n",
    "1. Toda transformação deve ser realizada **tanto no conjunto de teste quanto no conjunto final**.\n",
    "\n",
    "## Finalizando nosso dataset de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_adults = X_train[\"adults\"].mean()\n",
    "sig_adults = X_train[\"adults\"].std()\n",
    "mask_cheby_adults = (X_train[\"adults\"] > (mu_adults - 5 * sig_adults)) & (\n",
    "    X_train[\"adults\"] < (mu_adults + 5 * sig_adults)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_child = X_train[\"children_imp\"].mean()\n",
    "sig_child = X_train[\"children_imp\"].std()\n",
    "mask_cheby_child = (X_train[\"children_imp\"] > (mu_child - 5 * sig_child)) & (\n",
    "    X_train[\"children_imp\"] < (mu_child + 5 * sig_child)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q25 = np.quantile(X_train[\"lead_time\"], 0.25)\n",
    "q75 = np.quantile(X_train[\"lead_time\"], 0.75)\n",
    "iqr = q75 - q25\n",
    "mask_iqr_lead_time = (X_train[\"lead_time\"] > (q25 - 1.5 * iqr)) & (\n",
    "    X_train[\"lead_time\"] < (q75 + 1.5 * iqr)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inliner = (mask_iqr_lead_time) & (mask_cheby_child) & (mask_cheby_adults)\n",
    "print(f\"Removendo {np.round(100*(1-mask_inliner.sum()/X_train.shape[0]), 2)}% do Train-set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nout = X_train.loc[mask_inliner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numerical = X_train_nout[num_var]\n",
    "X_sca = pd.DataFrame(\n",
    "    scaler.transform(X_train_numerical),\n",
    "    columns = scaler.get_feature_names_out(),\n",
    "    index = X_train_nout.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dum = pd.DataFrame(\n",
    "    ohe.transform(X_train_nout[ohe_vars]),\n",
    "    columns = ohe.get_feature_names_out(),\n",
    "    index = X_train_nout.index\n",
    ")\n",
    "X_dum['is_company'] = X_train_nout['is_company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = pd.concat([X_sca, X_dum], axis = 1)\n",
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalizando nosso dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_na_company = X_test[\"company\"].isna()\n",
    "X_test.loc[mask_na_company, \"is_company\"] = 0\n",
    "X_test.loc[~mask_na_company, \"is_company\"] = 1\n",
    "\n",
    "X_test['country_imp'] = country_imputer.transform(X_test[[\"country\"]])\n",
    "X_test['children_imp'] = children_imputer.transform(X_test[[\"children\"]])\n",
    "X_test['country_grp'] = X_test['country_imp'].map(dict_country)\n",
    "X_test['country_grp'] = X_test['country_grp'].fillna('Others')\n",
    "X_test['num_meal'] = ordinal.transform(X_test[[\"meal\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_numerical = X_test.loc[:, num_var]\n",
    "X_sca_test = pd.DataFrame(\n",
    "    scaler.transform(X_test_numerical),\n",
    "    columns = scaler.get_feature_names_out(),\n",
    "    index = X_test_numerical.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dum_test = pd.DataFrame(\n",
    "    ohe.transform(X_test[ohe_vars]),\n",
    "    columns = ohe.get_feature_names_out(),\n",
    "    index = X_test.index\n",
    ")\n",
    "X_dum_test['is_company'] = X_test['is_company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = pd.concat([X_sca_test, X_dum_test], axis = 1)\n",
    "X_test_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando nossos conjuntos de teste e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_train = X_train_final\n",
    "tb_train['is_cancelled'] = y_train\n",
    "tb_train.to_csv('data/tb_hotel_train_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_test = X_test_final\n",
    "tb_test['is_cancelled'] = y_test\n",
    "tb_test.to_csv('data/tb_hotel_test_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXTRA** - Criando um *wrapper*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_objects(dados_treinamento):\n",
    "    # Limpando outliers\n",
    "    q25 = np.quantile(dados_treinamento[\"lead_time\"], 0.25)\n",
    "    q75 = np.quantile(dados_treinamento[\"lead_time\"], 0.75)\n",
    "    iqr = q75 - q25\n",
    "    mask_iqr = (dados_treinamento[\"lead_time\"] > (q25 - 1.5 * iqr)) & (dados_treinamento[\"lead_time\"] < (q75 + 1.5 * iqr))\n",
    "    dados_treinamento = dados_treinamento[mask_iqr].copy()\n",
    "    \n",
    "    # Criando imputers\n",
    "    country_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    dados_treinamento['country_imp'] = country_imputer.fit_transform(dados_treinamento[[\"country\"]])\n",
    "    children_imputer = SimpleImputer(strategy=\"median\")\n",
    "    dados_treinamento['children_imp'] = children_imputer.fit_transform(dados_treinamento[[\"children\"]])\n",
    "\n",
    "    # Criando grupos de países\n",
    "    tb_niveis_country = dados_treinamento[['country_imp']].value_counts().reset_index().rename({0 : 'num_obs'}, axis = 1)\n",
    "    mask_niveis = tb_niveis_country[\"num_obs\"] > (sum(tb_niveis_country[\"num_obs\"]) * 0.01)\n",
    "    tb_niveis_country.loc[mask_niveis, \"country_grp\"] = tb_niveis_country[\"country_imp\"]\n",
    "    tb_niveis_country.loc[~mask_niveis, \"country_grp\"] = \"Others\"\n",
    "    tb_niveis_country.index = tb_niveis_country[\"country_imp\"]\n",
    "    tb_niveis_country = tb_niveis_country.drop([\"num_obs\", \"country_imp\"], axis=1)\n",
    "    dict_country = tb_niveis_country.to_dict()[\"country_grp\"]\n",
    "    dados_treinamento['country_grp'] = dados_treinamento['country_imp'].map(dict_country)\n",
    "\n",
    "    # Criando OrdinalEncoder para Meal\n",
    "    ordinal = OrdinalEncoder(categories=[[\"Undefined\", \"SC\", \"BB\", \"HB\", \"FB\"]])\n",
    "    dados_treinamento['num_meal'] = ordinal.fit_transform(dados_treinamento[[\"meal\"]])\n",
    "\n",
    "    # Criando OneHotEncoder para variáveis categóricas\n",
    "    ohe_var = ['country_grp']\n",
    "    ohe = OneHotEncoder(sparse=False, drop=\"first\", handle_unknown=\"ignore\")\n",
    "    ohe.fit(dados_treinamento[ohe_var])\n",
    "\n",
    "    # Criando normalizador\n",
    "    num_var = ['lead_time', 'adults', 'num_meal', 'children_imp']\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(dados_treinamento[num_var])\n",
    "    return country_imputer, children_imputer, dict_country, ohe, ordinal, scaler\n",
    "\n",
    "\n",
    "def transform_data(dados_originais, country_imputer, children_imputer, dict_country, ohe, ordinal, scaler):\n",
    "    mask_na_company = dados_originais[\"company\"].isna()\n",
    "    dados_originais.loc[mask_na_company, \"is_company\"] = 0\n",
    "    dados_originais.loc[~mask_na_company, \"is_company\"] = 1\n",
    "\n",
    "    dados_originais['country_imp'] = country_imputer.transform(dados_originais[[\"country\"]])\n",
    "    dados_originais['children_imp'] = children_imputer.transform(dados_originais[[\"children\"]])\n",
    "    dados_originais['country_grp'] = dados_originais['country_imp'].map(dict_country)\n",
    "    dados_originais['country_grp'] = dados_originais['country_grp'].fillna('Others')\n",
    "    dados_originais['num_meal'] = ordinal.transform(dados_originais[[\"meal\"]])\n",
    "\n",
    "    ohe_var = ['country_grp']\n",
    "    X_dummies = pd.DataFrame(\n",
    "        ohe.transform(dados_originais[ohe_var]),\n",
    "        columns = ohe.get_feature_names_out(),\n",
    "        index = dados_originais.index\n",
    "    )\n",
    "    X_dummies['is_company'] = dados_originais['is_company']\n",
    "\n",
    "    num_var = ['lead_time', 'adults', 'num_meal', 'children_imp']\n",
    "    X_numerical = pd.DataFrame(\n",
    "        scaler.transform(dados_originais[num_var]),\n",
    "        columns = scaler.get_feature_names_out(),\n",
    "        index = dados_originais.index\n",
    "    )\n",
    "\n",
    "    return pd.concat([X_dummies, X_numerical], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var = [\"lead_time\", \"country\", \"company\", \"children\", \"adults\", \"meal\"]\n",
    "y_var = \"is_cancelled\"\n",
    "X = tb_hotel[X_var]\n",
    "y = tb_hotel[y_var]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_imputer, children_imputer, dict_country, ohe, ordinal, scaler = fit_objects(X_train)\n",
    "X_train_final = transform_data(X_train, country_imputer, children_imputer, dict_country, ohe, ordinal, scaler)\n",
    "X_test_final = transform_data(X_test, country_imputer, children_imputer, dict_country, ohe, ordinal, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014f4a4a5af8f0104b12c029e500f4146d6d785e8cf714d2a35b7a9514230cd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
