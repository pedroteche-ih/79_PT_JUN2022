{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_hotel_train = pd.read_csv(\"data/tb_hotel_train_clean.csv\")\n",
    "tb_hotel_test = pd.read_csv(\"data/tb_hotel_test_clean.csv\")\n",
    "\n",
    "tb_hotel_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = [\"lead_time\", \"adr\"]\n",
    "X_train = tb_hotel_train[x_var]\n",
    "X_test = tb_hotel_test[x_var]\n",
    "y_train = tb_hotel_train[\"is_cancelled\"]\n",
    "y_test = tb_hotel_test[\"is_cancelled\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística\n",
    "\n",
    "Antes de mergulharmos nos algoritmos `KNearestNeighborsClassifier` e `DecisionTreeClassifier`, vamos relembrar o que vimos na aula passada sobre o método mais simples de classificação: a **regressão logística**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fit = LogisticRegression()\n",
    "log_fit.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um modelo de classificação prevê a **probabilidade** de um evento acontecer - nossa regressão está prevendo a probabilidade de uma reserva ser cancelada dado um `lead time` e `average daily rate`. Podemos visualizar essas probabilidades utilizando o método `.predict_proba()` (lembrando que ele retorna os **2 vetores de probabilidade**, a chance de *não-cancelamento* e *cancelamento*!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_log_fit = X_train.copy()\n",
    "tb_log_fit[\"pred_prob\"] = log_fit.predict_proba(X_train)[:, 1]\n",
    "tb_log_fit[\"is_cancelled\"] = y_train\n",
    "sns.scatterplot(data=tb_log_fit, x=\"lead_time\", y=\"pred_prob\", hue=\"adr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plot_decision_regions(\n",
    "    np.array(tb_log_fit[[\"lead_time\", \"adr\"]]),\n",
    "    np.array(tb_log_fit[\"is_cancelled\"]),\n",
    "    log_fit,\n",
    "    scatter_kwargs={\"alpha\": 0.001},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar o método `.predict()` para gerar previsões de classificação - uma previsão binária construída a partir do *thresholding* da probabilidade de cancelamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_log = log_fit.predict(X_test)\n",
    "y_test_log[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_pred_log = pd.DataFrame({\"y_real\": y_test, \"y_previsto\": y_test_log})\n",
    "tb_pred_log.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medindo o Erro de Previsão\n",
    "\n",
    "Na aula passada introduzimos o problema de como calcular a precisão de um modelo de classificação. Não poddemos **medir a acurácia da função de probabilidade**: *ela não é observada*. Precisamos utilizar as previsões de classificação para medir o erro do modelo. Para tanto, vamos ver algumas **métricas** diferentes para modelos de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia\n",
    "\n",
    "A **acurácia** é a medida mais simples de erro dos modelos de classficação:\n",
    "\n",
    "$$Acc. = \\frac{\\text{Núm. de Previsões Corretas}}{\\text{Núm. de Previsões Totais}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_test_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acúracia é uma medida razoável quando nossa variável resposta não é *desbalanceada*, ou seja, contém o mesmo número de observações em cada classe.\n",
    "\n",
    "Não é o caso em nosso problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Núm. de Cancelamentos no Teste: {np.sum(y_test)}\")\n",
    "print(f\"Núm. de Reservas no Teste: {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão\n",
    "\n",
    "A maior parte dos problemas de classficação **não são balanceados**: em geral a classe que desejamos prever é a classe minoritária (por exemplo, fraudes em um banco ou então churn em um serviço de assinatura). Nesses casos a acurácia **não é uma boa medida de erro**!\n",
    "\n",
    "Além disso, muitas vezes, problemas de classificação tem **custos** diferentes associados aos diferentes erros de previsão (*i.e.:* prever que uma reserva será cancelada quando ela não é vs. prever um não-cancelamento quando ela é cancelada).\n",
    "\n",
    "Vamos utilizar uma **Matriz de Confusão** para visualizar os **2 tipos de erro de classificação**. Primeiro, vamos criar a matriz manualmente para entendermos melhor o que está por trás da visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(tb_pred_log[\"y_real\"], tb_pred_log[\"y_previsto\"], margins=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos utilizar as funções `confusion_matrix` e `ConfusionMatrizDisplay` para visualizar nossa matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "cf = confusion_matrix(y_test, y_test_log)\n",
    "cf_plot = ConfusionMatrixDisplay(cf)\n",
    "cf_plot.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisão e Recall\n",
    "\n",
    "A partir da Matriz de Confusão podemos entender as duas principais métricas do erro de classificação: **Precisão** e **Recall (ou *sensibilidade*)**. As duas métricas são utilizadas **em conjunto** para mitigar os riscos de sub-avaliarmos o erro na classe minoritária.\n",
    "\n",
    "#### Precisão\n",
    "\n",
    "A **Precisão** é uma medida de erro baseada **nas previsões positivas**, ou seja, **na segunda COLUNA da nossa matriz de confusão**. Ela é definida como:\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{Positivos Verdadeiros}}{\\text{Positivos Verdadeiros} + \\text{Falsos Positivos}}$$\n",
    "\n",
    "Conceitualmente, a precisão mede o **quão corretas as previsões positivas do nosso modelo são**. Em nosso problema atual, ela mede **a % de previsões de cancelamentos que DE FATO serão cancelamentos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(precision_score(y_test, y_test_log), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall (ou *sensibilidade*)\n",
    "\n",
    "O **Recall** é uma medida de erro baseada nos **eventos positivos**, ou seja, na **segunda LINHA da nossa matriz de confusão**. Ela é definida como:\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{Positivos Verdadeiros}}{\\text{Positivos Verdadeiros} + \\text{Falsos Negativos}} $$\n",
    "\n",
    "Conceitualmente, o *recall* mede a **capacidade do nosso modelo de prever eventos positivos**. Em nosso exemplo, ele mede **a % de cancelamentos REAIS que nosso modelo prevê corretamente**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(recall_score(y_test, y_test_log), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinando Precisão e Recall - F1 Score\n",
    "\n",
    "As duas medidas apresentadas acima mede **qualidades opostas do nosso modelo**: a capacidade de fazer previsões positivas corretamente e a capacidade de prever todos os eventos positivos. Para combinar as duas medidas em uma só tradicionalmente utilizamos o F1-Score (a média harmonica entre as duas medidas):\n",
    "\n",
    "$$ \\text{F1-Score} = 2 \\frac{\\text{Precision} * \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "\n",
    "**Quanto mais próximo o F1 está de 1, melhor nosso modelo!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_test_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador kNN\n",
    "\n",
    "O primeiro algoritmo de ML que vamos analisar hoje é o `KNeighborsClassifier`, a implatanção na `sklearn` do algoritmo **kNN**. A idéia por trás do algoritmo kNN é simples: observações que são semelhantes entre si terão resultados semelhantes entre si.\n",
    "\n",
    "Em nosso modelo, reservas com **lead time** e **adr** semelhantes terão taxas de cancelamento semelhantes. O algoritmo **kNN** busca as *k* observações mais próximas da observação que queremos prever e as utiliza para estimar a *probabilidade de cancelamento*. Um caso particular do kNN é quando k = 1: neste caso, buscamos a observação mais semelhante àquela que queremos realizar uma previsão e utilizamos o seu resultado como valor previsto!\n",
    "\n",
    "![kNN](images/knn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fit = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_fit.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos utilizar nosso kNN com k = 50 para visualizar as probabilidades previstas para o conjunto de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_knn_fit = X_train.copy()\n",
    "tb_knn_fit[\"pred_prob\"] = knn_fit.predict_proba(X_train)[:, 1]\n",
    "tb_knn_fit[\"is_cancelled\"] = y_train\n",
    "sns.scatterplot(data=tb_knn_fit, x=\"lead_time\", y=\"pred_prob\", hue=\"adr\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como a probabilidade prevista, a superficie de decisão do algoritmo é extremamente irregular. Isso aponta para as qualidades e limitações do **kNN**:\n",
    "\n",
    "1. Alta não-linearidade;\n",
    "1. Dificuldade de generalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plot_decision_regions(\n",
    "    np.array(tb_knn_fit[[\"lead_time\", \"adr\"]]),\n",
    "    np.array(tb_knn_fit[\"is_cancelled\"]),\n",
    "    knn_fit,\n",
    "    scatter_kwargs={\"alpha\": 0.001},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando o erro\n",
    "\n",
    "Vamos comparar esse algoritmo rudimentar à nossa regressão logística utilizando as métricas que aprendemos mais cedo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_knn = knn_fit.predict(X_test)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].set_title(\"C.M. Reg.\")\n",
    "cf_log = confusion_matrix(y_test, y_test_log)\n",
    "cf_log_plot = ConfusionMatrixDisplay(cf_log)\n",
    "cf_log_plot.plot(ax=ax[0])\n",
    "ax[1].set_title(\"C.M. kNN\")\n",
    "cf_knn = confusion_matrix(y_test, y_test_knn)\n",
    "cf_knn_plot = ConfusionMatrixDisplay(cf_knn)\n",
    "cf_knn_plot.plot(ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erro Regressão:\")\n",
    "print(f\"Precisão: {np.round(precision_score(y_test, y_test_log), 2)}\")\n",
    "print(f\"Recall: {np.round(recall_score(y_test, y_test_log), 2)}\")\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_log), 2)}\\n\")\n",
    "print(\"Erro kNN:\")\n",
    "print(f\"Precisão: {np.round(precision_score(y_test, y_test_knn), 2)}\")\n",
    "print(f\"Recall: {np.round(recall_score(y_test, y_test_knn), 2)}\")\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_knn), 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizando Hiperparâmetros\n",
    "\n",
    "O número de vizinhos que consideramos no algoritmo **kNN** é o nosso primeiro contato com *hiperparâmetros*. **Hiperparâmetros** são como *definimos a forma que um algoritmo de ML* se comporta: ao contrário das regressões (linear e logística), um mesmo algoritmo pode ter diferentes utilizações - definidas pelo seu **conjunto de hiperparâmetros**. \n",
    "\n",
    "**SEMPRE** que utilizamos um algoritmo de ML **precisamos** otimizar os hiperparâmetros, ou seja, buscar o conjunto de hiperparâmetros com melhor performance para nosso problema. Vamos otimizar nosso algoritmo **kNN** para o problema atual começando pelo principal hiperparâmetro deste algoritmo: **k**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fit = KNeighborsClassifier(n_neighbors=100)\n",
    "knn_fit.fit(X_train, y_train)\n",
    "\n",
    "y_test_knn = knn_fit.predict(X_test)\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_knn), 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A melhor forma de otimizar um hiperparâmetro é fazendo buscas exaustivas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5, 56, 10):\n",
    "    print(f\"Testanto k = {k}\")\n",
    "    knn_fit = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_fit.fit(X_train, y_train)\n",
    "\n",
    "    y_test_knn = knn_fit.predict(X_test)\n",
    "    print(f\"F1-Score: {np.around(f1_score(y_test, y_test_knn), 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O segundo **hiperparâmetro** do algoritmo **kNN** é a *ponderação* (`weights = \"distance\"` na implantação da `sklearn`): se devemos considerar a distância dos k-vizinhos como forma de ponderar seus diferentes resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5, 56, 10):\n",
    "    print(f\"Testanto k = {k}\")\n",
    "    knn_fit = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "    knn_fit.fit(X_train, y_train)\n",
    "\n",
    "    y_test_knn = knn_fit.predict(X_test)\n",
    "    print(f\"F1-Score: {np.around(f1_score(y_test, y_test_knn), 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que fizemos uma busca *esparsa*, podemos construir uma busca **densa** mais específica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2, 15):\n",
    "    print(f\"Testanto k = {k}\")\n",
    "    knn_fit = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "    knn_fit.fit(X_train, y_train)\n",
    "\n",
    "    y_test_knn = knn_fit.predict(X_test)\n",
    "    print(f\"F1-Score: {np.around(f1_score(y_test, y_test_knn), 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nosso problema parece que temos alguns pontos ótimos - vamos escolher um e construir a versão final de nosso algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fit = KNeighborsClassifier(n_neighbors=10, weights=\"distance\")\n",
    "knn_fit.fit(X_train, y_train)\n",
    "\n",
    "y_test_knn = knn_fit.predict(X_test)\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_knn), 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvores de Decisão\n",
    "\n",
    "O segundo algoritmo que veremos hoje é a **árvore de decisão**, implantada na `sklearn` através do `DecisionTreeClassifier`. O algoritmo da árvore de decisão funciona buscando **cortes** em nossos *features* que maximizem a diferença da nossa variável resposta nos grupos de observações em cada lado do corte.\n",
    "\n",
    "Em cada etapa do algoritmo, buscamos cortes para todos os grupos criados até então. Este processo pode ser repetido até cada grupo conter apenas uma observação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_fit = DecisionTreeClassifier(max_depth=4)\n",
    "dt_fit.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_dt_fit = X_train.copy()\n",
    "tb_dt_fit[\"pred_prob\"] = dt_fit.predict_proba(X_train)[:, 1]\n",
    "tb_dt_fit[\"is_cancelled\"] = y_train\n",
    "sns.scatterplot(data=tb_dt_fit, x=\"lead_time\", y=\"pred_prob\", hue=\"adr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plot_decision_regions(\n",
    "    np.array(tb_dt_fit[[\"lead_time\", \"adr\"]]),\n",
    "    np.array(tb_dt_fit[\"is_cancelled\"]),\n",
    "    dt_fit,\n",
    "    scatter_kwargs={\"alpha\": 0.001},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando a Árvore\n",
    "\n",
    "Podemos construir uma visualização dos cortes construídos pelo agoritmo utilizando a função `plot_tree`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 10))\n",
    "plot_tree(dt_fit, feature_names=X_train.columns, filled=True, fontsize=10);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na árvore acima, podemos ver os diferentes **cortes** (grupos intermediários, com o *feature* e o valor do corte) e as **folhas** de nossa árvore (os últimos *nós* do grafo, contendo a proporção entre não-cancelamentos e cancelamentos).\n",
    "\n",
    "## Comparando o Erro\n",
    "\n",
    "Vamos utilizar a matriz de confusão e as métricas de classificação para comparar a performance de nossos modelos até agora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_dt = dt_fit.predict(X_test)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].set_title(\"C.M. Reg.\")\n",
    "cf_log = confusion_matrix(y_test, y_test_log)\n",
    "cf_log_plot = ConfusionMatrixDisplay(cf_log)\n",
    "cf_log_plot.plot(ax=ax[0])\n",
    "ax[1].set_title(\"C.M. kNN\")\n",
    "cf_knn = confusion_matrix(y_test, y_test_knn)\n",
    "cf_knn_plot = ConfusionMatrixDisplay(cf_knn)\n",
    "cf_knn_plot.plot(ax=ax[1])\n",
    "ax[2].set_title(\"C.M. Árvore de Decisão\")\n",
    "cf_dt = confusion_matrix(y_test, y_test_dt)\n",
    "cf_knn_plot = ConfusionMatrixDisplay(cf_dt)\n",
    "cf_knn_plot.plot(ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erro Regressão:\")\n",
    "print(f\"Precisão: {np.round(precision_score(y_test, y_test_log), 2)}\")\n",
    "print(f\"Recall: {np.round(recall_score(y_test, y_test_log), 2)}\")\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_log), 2)}\\n\")\n",
    "print(\"Erro kNN:\")\n",
    "print(f\"Precisão: {np.round(precision_score(y_test, y_test_knn), 2)}\")\n",
    "print(f\"Recall: {np.round(recall_score(y_test, y_test_knn), 2)}\")\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_knn), 2)}\\n\")\n",
    "print(\"Erro Árvore de Decisão:\")\n",
    "print(f\"Precisão: {np.round(precision_score(y_test, y_test_dt), 2)}\")\n",
    "print(f\"Recall: {np.round(recall_score(y_test, y_test_dt), 2)}\")\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_dt), 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizando Hiperparâmetros\n",
    "\n",
    "Como todo algoritmo de ML, as árvores de decisão tem **hiperparâmetros** que precisam ser otimizados. Vamos começar com o principal hiperparâmetro das A.Ds: a **profundidade máxima** (`max_depth =` na implantação da `sklearn`).\n",
    "\n",
    "A profundidade máxima determina o número máximo de cortes sucessivos que podemos fazer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_dt = []\n",
    "\n",
    "for d in range(4, 150, 10):\n",
    "    dt_fit = DecisionTreeClassifier(max_depth=d)\n",
    "    dt_fit.fit(X_train, y_train)\n",
    "    y_test_dt = dt_fit.predict(X_test)\n",
    "    f1_score_dt.append(f1_score(y_test, y_test_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_depth_f1 = pd.DataFrame({\"f1\": f1_score_dt})\n",
    "tb_depth_f1[\"depth\"] = list(range(4, 150, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar a evolção do erro conforme aumentamos a profundidade máxima da A.D.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=tb_depth_f1, x=\"depth\", y=\"f1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que as melhores profundidades são acima de ~40 (com pouca melhoria entre 40 e 140). Vamos analisar outro hiperparâmetro crítico das árvores de decisão.\n",
    "\n",
    "### Além do `max_depth`\n",
    "\n",
    "O segundo parâmetro crítico em uma árvore de decisão é o tamanho mínimo de cada galho (em # de observações): ao aumentarmos o número mínimo de observações em cada corte reduzimos o número de cortes possíveis em partes menos densas de nossa árvore (ao contrário da profundidade, que controla a árvore de forma uniforme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_dt = []\n",
    "hp_dt = []\n",
    "depth_range = range(4, 150, 10)\n",
    "mss_range = range(2, 500, 50)\n",
    "\n",
    "for depth in depth_range:\n",
    "    for mss in mss_range:\n",
    "        dt_fit = DecisionTreeClassifier(max_depth=depth, min_samples_split=mss)\n",
    "        dt_fit.fit(X_train, y_train)\n",
    "        y_test_dt = dt_fit.predict(X_test)\n",
    "        f1_score_dt.append(f1_score(y_test, y_test_dt))\n",
    "        hp_dt.append((depth, mss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_hp_dt = pd.DataFrame(\n",
    "    {\n",
    "        \"f1\": f1_score_dt,\n",
    "    }\n",
    ")\n",
    "tb_hp_dt[[\"depth\", \"min_sample_split\"]] = hp_dt\n",
    "tb_hp_dt.sort_values(\"f1\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_fit = DecisionTreeClassifier(max_depth=124, min_samples_split=2)\n",
    "dt_fit.fit(X_train, y_train)\n",
    "y_test_dt = dt_fit.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_dt = dt_fit.predict(X_test)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].set_title(\"C.M. Reg.\")\n",
    "cf_log = confusion_matrix(y_test, y_test_log)\n",
    "cf_log_plot = ConfusionMatrixDisplay(cf_log)\n",
    "cf_log_plot.plot(ax=ax[0])\n",
    "ax[1].set_title(\"C.M. kNN\")\n",
    "cf_knn = confusion_matrix(y_test, y_test_knn)\n",
    "cf_knn_plot = ConfusionMatrixDisplay(cf_knn)\n",
    "cf_knn_plot.plot(ax=ax[1])\n",
    "ax[2].set_title(\"C.M. Árvore de Decisão\")\n",
    "cf_dt = confusion_matrix(y_test, y_test_dt)\n",
    "cf_knn_plot = ConfusionMatrixDisplay(cf_dt)\n",
    "cf_knn_plot.plot(ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erro Regressão:\")\n",
    "print(f\"Precisão: {np.round(precision_score(y_test, y_test_log), 2)}\")\n",
    "print(f\"Recall: {np.round(recall_score(y_test, y_test_log), 2)}\")\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_log), 2)}\\n\")\n",
    "print(\"Erro kNN:\")\n",
    "print(f\"Precisão: {np.round(precision_score(y_test, y_test_knn), 2)}\")\n",
    "print(f\"Recall: {np.round(recall_score(y_test, y_test_knn), 2)}\")\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_knn), 2)}\\n\")\n",
    "print(\"Erro Árvore de Decisão:\")\n",
    "print(f\"Precisão: {np.round(precision_score(y_test, y_test_dt), 2)}\")\n",
    "print(f\"Recall: {np.round(recall_score(y_test, y_test_dt), 2)}\")\n",
    "print(f\"F1-Score: {np.around(f1_score(y_test, y_test_dt), 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plot_decision_regions(\n",
    "    np.array(tb_dt_fit[[\"lead_time\", \"adr\"]]),\n",
    "    np.array(tb_dt_fit[\"is_cancelled\"]),\n",
    "    dt_fit,\n",
    "    scatter_kwargs={\"alpha\": 0.001},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na próxima aula veremos quais os problemas associados à superficies de decisão complexas: *overfitting*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014f4a4a5af8f0104b12c029e500f4146d6d785e8cf714d2a35b7a9514230cd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
