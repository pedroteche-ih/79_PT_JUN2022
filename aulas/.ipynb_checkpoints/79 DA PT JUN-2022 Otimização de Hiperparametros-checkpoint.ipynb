{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimizando Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando e pré-processando Ames Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_housing = pd.read_csv(\"data/tb_ames_housing.csv\")\n",
    "tb_housing = tb_housing.dropna(axis=1)\n",
    "tb_housing = tb_housing.drop(\"Id\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_housing.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos separar as variáveis numéricas e categóricas, guardando os nomes de cada coluna e duas listas distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = list(tb_housing.select_dtypes(\"object\").columns)\n",
    "num_vars = list(tb_housing.select_dtypes(include=np.number).drop(\"SalePrice\", axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos utilizar criar um OneHotEncoder capaz de lidar com os features salvos na lista `cat_vars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_fit = OneHotEncoder(drop=\"first\", sparse = False)\n",
    "ohe_fit.fit(tb_housing[cat_vars])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos separar o conjunto de treinamento e teste e criar um StandardScaler a partir dos dados de treinamento. Após a separação vamos criar uma nova matriz de dados através da concatenação das variáveis categóricas codificadas como variáveis binárias e das variáves numéricas normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tb_housing[cat_vars + num_vars], tb_housing['SalePrice'], test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = np.column_stack([scaler.transform(X_train[num_vars]), ohe_fit.transform(X_train[cat_vars])])\n",
    "X_test_t = np.column_stack([scaler.transform(X_test[num_vars]), ohe_fit.transform(X_test[cat_vars])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando overfitting\n",
    "\n",
    "Como vimos nas últimas semanas, os algoritmos de ML são muito diferentes das regressões linear e logistica: enquanto estes modelos simples são definidos pelas variáveis de entrada, os modelos de ML são definidos também por hiperparâmetros. Também vimos que métodos como as árvores de decisão são muitas vezes capaz de explicar *perfeitamente* os dados de treinamento sem que isso se reflita no conjunto de teste.\n",
    "\n",
    "Essa capacidade dos modelos de ML de aprenderem estruturas complexas é ao mesmo tempo seu ponto forte e um risco: se ajustarmos os parâmetros de um modelo erroneamente podemos terminar achando que o modelo tem uma performance muito melhor do que realmente terá. A divisão em conjuntos de treinamento e teste mitiga muito desse risco, mas não nos dá, a priori, uma forma de encontrar o melhor conjunto de parâmetros para um dado problema.\n",
    "\n",
    "Nesta seção vamos visualizar como o overfitting acontece comparando o erro no conjunto de treinamento e o erro no conjunto de teste. A partir desse entendimento poderemos traçar estratégias para encontrar o melhor conjunto de hiperparâmetros para nossos dados sem que soframos nem com underfitting (variáveis tem mais poder explicativo do que modelo representa) ou overfitting (modelo não generaliza)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_optim = [int(x) for x in np.linspace(1, 20, 20)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_train_list = []\n",
    "erro_test_list = []\n",
    "depth_list = []\n",
    "for depth in depth_optim:\n",
    "    tree_fit = DecisionTreeRegressor(max_depth = depth)\n",
    "    tree_fit.fit(X_train_t, y_train)\n",
    "    erro_train = mean_squared_error(y_train, tree_fit.predict(X_train_t))\n",
    "    erro_test = mean_squared_error(y_test, tree_fit.predict(X_test_t))\n",
    "    erro_train_list.append(erro_train)\n",
    "    erro_test_list.append(erro_test)\n",
    "    depth_list.append(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como nas tarefas de classificação, a complexidade de uma árvore de decisão é ligada, principalmente, à três parâmetros fundamentais:\n",
    "\n",
    "* **max_depth**: a profundidade máxima da árvore, medida em número de splits entre as folhas e a raiz;\n",
    "* **min_samples_split**: o menor número de pontos necessário em um galho para que um split seja feito;\n",
    "* **min_samples_leaf**: o menor número de pontos em cada folha.\n",
    "\n",
    "Conforme aumentamos a `max_depth` e diminuimos o `min_samples_split` e `min_samples_leaf` aumentamos a complexidade de nossa árvore e, como em qualquer modelo, conforme aumentamos a complexidade aumentamos o risco  de sofrer com overfitting. No código acima variamos a complexidade da árvore aumentando sua profundidade de 1 à 20. Vamos visualizar o overfitting comparando o erro do modelo no conjunto de teste contra o conjunto de treinamento conforme aumentamos a complexidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_overfit = pd.DataFrame({'depth' : depth_list, 'erro_train_list' : erro_train_list, 'erro_test_list' : erro_test_list})\n",
    "sns.lineplot(data = tb_overfit, x= 'depth', y= 'erro_train_list')\n",
    "sns.lineplot(data = tb_overfit, x= 'depth', y= 'erro_test_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comoi podemos ver, inicialmente o aumento de complexidade da árvore reduz o erro tanto no conjunto de teste quanto no conjunto de treinamento. Conforme a complexidade aumenta, a velocidade de melhoría no conjunto teste cai, até que se estabiliza (e muitas vezes vemos o erro crescer a partir deste ponto).\n",
    "\n",
    "O melhor modelo é aquele que tem o melhor erro (aproveita toda informação disponível) e a menor complexidade (maior capacidade de generalização). No gráfico acima podemos ver que, no caso atual, a árvore com profundidade 4 se aproxima desse ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fit = DecisionTreeRegressor(max_depth = 6)\n",
    "tree_fit.fit(X_train_t, y_train)\n",
    "erro_train = mean_squared_error(y_train, tree_fit.predict(X_train_t))\n",
    "erro_test = mean_squared_error(y_test, tree_fit.predict(X_test_t))\n",
    "print(f\"RMSE Train: {np.sqrt(erro_train)}\\nRMSE Test: {np.sqrt(erro_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando o gridsearch para automatizar a busca\n",
    "\n",
    "A tarefa realizada acima através de um loop é tão comum que podemos utilizar uma série de funções específicas para realizar a avaliação automática de hiperparâmetros. Alguns nomes importantes nesse processo:\n",
    "\n",
    "* **Espaço de Hiperparâmetros**: no exemplo acima varíamos apenas a profundidade da árvore que estávamos construindo - neste caso o espaço de hiperparâmetros era o vetor [1, 2, 3 ... 19, 20] (`np.linspace(1, 20, 20)`). Veremos abaixo um exemplo onde este espaço é composto por mais vetores.\n",
    "* **Busca com Validação Cruzada**: para manter o nosso conjunto teste original fora da busca de hiperparâmetros utilizaremos validação cruzada no conjunto de treinamento - para cada combinação possível dos nossos vetores de hiperparâmetros construiremos 5 conjuntos de teste sobre o qual avaliaremos o modelo. Utilizaremos esses 5 conjuntos para calcular o erro médio associado à um conjunto de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos usar o `GridSearchCV` para realizar a avaliação que fizemos através do loop acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth' : [int(x) for x in np.linspace(1, 20, 20)]\n",
    "}\n",
    "tree_fit = DecisionTreeRegressor()\n",
    "grid_fit = GridSearchCV(tree_fit, param_grid, cv = 5)\n",
    "grid_fit.fit(X_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_train = mean_squared_error(y_train, grid_fit.predict(X_train_t))\n",
    "erro_test = mean_squared_error(y_test, grid_fit.predict(X_test_t))\n",
    "print(grid_fit.best_estimator_)\n",
    "print(f\"RMSE Train: {np.sqrt(erro_train)}\\nRMSE Test: {np.sqrt(erro_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `GridSearchCV` tem duas grandes vantagens sobre o nosso loop original:\n",
    "\n",
    "1. Realiza automaticamente a busca utilizando validação cruzada;\n",
    "1. Cria automaticamente espaços de parâmetros mais complexos.\n",
    "\n",
    "Para entender melhor o segundo ponto vamos expandir nossa busca para contemplar os outros 2 hiperparâmetros fundamentais de complexidade das árvores de decisão (`min_samples_split` e `min_samples_leaf`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth' : [int(x) for x in np.linspace(1, 50, 10)],\n",
    "    'min_samples_split' : [int(x) for x in np.linspace(2, 40, 10)],\n",
    "    'min_samples_leaf' : [int(x) for x in np.linspace(1, 20, 10)]\n",
    "}\n",
    "tree_fit = DecisionTreeRegressor()\n",
    "grid_fit = GridSearchCV(tree_fit, param_grid, cv = 50)\n",
    "grid_fit.fit(X_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_fit.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O espaço de hiperparâmetros definido acima não é composto apenas por um vetor, mas por um **grade**: o `GridSearchCV` vai testar todos os pontos dessa grade, ou seja, todas as combinações de hiperparâmetros possíveis a partir dos vetores definidos dentro do dicionário `param_grid`.\n",
    "\n",
    "Podemos utilizar o atributo `.cv_results_` para acessar os resultados de cada fit feito pela busca. Temos que tomar cuidado com o erro apresentado aqui: ele é o `MSE * -1`, ou seja, quanto maior, melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_gridfit = pd.DataFrame(grid_fit.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_gridfit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_gridfit.sort_values('mean_test_score', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar gráficos e estatisticas descritivas para entender se a nossa busca foi suficiente ou se devemos extende-la em alguma direção não explorada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "sns.boxplot(data = tb_gridfit, x = 'param_max_depth', y = 'mean_test_score', ax = ax[0])\n",
    "sns.boxplot(data = tb_gridfit, x = 'param_min_samples_split', y = 'mean_test_score', ax = ax[1])\n",
    "sns.boxplot(data = tb_gridfit, x = 'param_min_samples_leaf', y = 'mean_test_score', ax = ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No gráfico acima podemos ver um gap do espaço contruído: temos poucas árvores de baixa profundidade (nenhuma entre 0 e 6 por exemplo). Como as buscas exaustivas são computacionalmente caras, podemos acabar deixando buracos inadivertidamente na grade de hiperparâmetros.\n",
    "\n",
    "Abaixo veremos uma segunda forma de fazer esta busca que nos permite aumentar os vetores percorridos sem aumentar o custo da busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_train = mean_squared_error(y_train, grid_fit.predict(X_train_t))\n",
    "erro_test = mean_squared_error(y_test, grid_fit.predict(X_test_t))\n",
    "print(grid_fit.best_estimator_)\n",
    "print(f\"RMSE Train: {np.sqrt(erro_train)}\\nRMSE Test: {np.sqrt(erro_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando buscas aleatória para acelerar o processo\n",
    "\n",
    "Ao invés de buscar exaustivamente todas as combinações, muitas vezes o ideal é começar utilizando uma busca aleatória: ao invés de buscar exaustivamente a grade de hiperparâmetros vamos *sortear* pontos dentro dessa grade para serem testados. As buscas aleatórias nos permitem percorrer um espaço maior com o mesmo custo que a busca exaustiva. No entanto podemos deixar passar o ponto *realmente ótimo* caso ele não seja sorteado. Por isso muitas vezes utilizamos uma busca aleatória para encontrar as melhores regiões no espaço de hiperparâmetros e então realizar buscas exaustivas nestas regiões.\n",
    "\n",
    "Vamos usar o `RandomizedSearchCV` para buscar um espaço maior de hiperparâmetros. A única diferença para o `GridSearchCV` é o parâmetro `n_iter = 1000` que define quantos pontos serão amostrados em nosso processo de busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth' : range(1, 150),\n",
    "    'min_samples_split' : range(2, 40),\n",
    "    'min_samples_leaf' : range(1, 20)\n",
    "}\n",
    "tree_fit = DecisionTreeRegressor()\n",
    "grid_fit = RandomizedSearchCV(tree_fit, param_grid, cv = 5, n_iter = 1000)\n",
    "grid_fit.fit(X_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_gridfit = pd.DataFrame(grid_fit.cv_results_)\n",
    "fig, ax = plt.subplots(1, 3, figsize = (25, 5))\n",
    "sns.boxplot(data = tb_gridfit, x = 'param_max_depth', y = 'mean_test_score', ax = ax[0])\n",
    "sns.boxplot(data = tb_gridfit, x = 'param_min_samples_split', y = 'mean_test_score', ax = ax[1])\n",
    "sns.boxplot(data = tb_gridfit, x = 'param_min_samples_leaf', y = 'mean_test_score', ax = ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nosso espaço é muito grande, os gráficos não são mais tão informativos... Podemos analisar os 10 melhores modelos que a busca aleatória encontrou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_gridfit.sort_values('mean_test_score', ascending= False).head(10)[['param_min_samples_split', 'param_min_samples_leaf', 'param_max_depth', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_train = mean_squared_error(y_train, grid_fit.predict(X_train_t))\n",
    "erro_test = mean_squared_error(y_test, grid_fit.predict(X_test_t))\n",
    "print(grid_fit.best_estimator_)\n",
    "print(f\"RMSE Train: {np.sqrt(erro_train)}\\nRMSE Test: {np.sqrt(erro_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1] + [1] + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth' : [4, 5, 6, 7] + [int(x) for x in np.linspace(11, 22, 5)] + [int(x) for x in np.linspace(30, 50, 5)] + [None],\n",
    "    'min_samples_split' : [1] + [int(x) for x in np.linspace(5, 15, 5)] + [int(x) for x in np.linspace(18, 26, 5)],\n",
    "    'min_samples_leaf' : [1] + [int(x) for x in np.linspace(5, 20, 10)]\n",
    "}\n",
    "tree_fit = DecisionTreeRegressor()\n",
    "grid_fit = GridSearchCV(tree_fit, param_grid, cv = 5)\n",
    "grid_fit.fit(X_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_train = mean_squared_error(y_train, grid_fit.predict(X_train_t))\n",
    "erro_test = mean_squared_error(y_test, grid_fit.predict(X_test_t))\n",
    "print(grid_fit.best_estimator_)\n",
    "print(f\"RMSE Train: {np.sqrt(erro_train)}\\nRMSE Test: {np.sqrt(erro_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizando etapas de pré-processamento\n",
    "\n",
    "Já vimos alguma formas de pré-processamento que também tem hiperparâmetros que causam impactos sobre o erro do modelo. Até agora vimos apenas técnicas de determinação desses atributos com base em características intrinsicas do modelo sendo aplicado (por exemplo, análise de variância representada quando utilizamos PCA). Vamos construir uma forma de inserir estes parâmetros no GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines de Modelagem - Simples\n",
    "\n",
    "Para fazer isso vamos utilizar pipelines - funções que agregam métodos de transformação, pré-processamento e modelos em uma única interface de train e predict. Vamos começar com um exemplo simples, utilizando PCA sobre as variáveis numéricas de nosso dataset, para tratar as muitas colinearidades presentes que estão causando problemas até no tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "tree_fit = DecisionTreeRegressor()\n",
    "\n",
    "pipeline = Pipeline([('SCALING', scaler), ('PCA', pca), ('MODEL', tree_fit)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora com nosso pipeline definido, vamos utiliza-lo como se fosse um modelo normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tb_housing[num_vars], tb_housing['SalePrice'], test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_train = mean_squared_error(y_train, pipeline.predict(X_train))\n",
    "erro_test = mean_squared_error(y_test, pipeline.predict(X_test))\n",
    "print(f\"RMSE Train: {np.sqrt(erro_train)}\\nRMSE Test: {np.sqrt(erro_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'PCA__n_components' : range(1, len(num_vars)), \n",
    "    'MODEL__max_depth' : range(1, 150),\n",
    "    'MODEL__min_samples_split' : range(2, 40),\n",
    "    'MODEL__min_samples_leaf' : range(1, 20),\n",
    "}\n",
    "\n",
    "grid_fit = RandomizedSearchCV(pipeline, param_grid, cv = 5, n_iter = 1000)\n",
    "grid_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_train = mean_squared_error(y_train, grid_fit.predict(X_train))\n",
    "erro_test = mean_squared_error(y_test, grid_fit.predict(X_test))\n",
    "print(grid_fit.best_params_)\n",
    "print(f\"RMSE Train: {np.sqrt(erro_train)}\\nRMSE Test: {np.sqrt(erro_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines de Modelagem - Compostas\n",
    "\n",
    "Agora vamos construir um pipeline capaz de lidar de forma independente com dados categóricos e numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tb_housing[num_vars+cat_vars], tb_housing['SalePrice'], test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca_num = PCA()\n",
    "num_pipeline = Pipeline([('SCALER', scaler), ('PCA', pca_num)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos um pipeline, `num_pipeline`, para tratar exclusivamente de variáveis numéricas. Vamos criar o outro braço do nosso pipeline completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar a função `SelectKBest` para selecionar as principais variáveis dummies que impactam nossa variável resposta. Vamos utilizar o GridSearch para otimizar o K (número de variáveis que manteremos no modelo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop = 'first', handle_unknown=\"ignore\")\n",
    "kbest = SelectKBest(score_func = f_regression)\n",
    "cat_pipeline = Pipeline([('OHE', ohe), ('KB', kbest)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir a etapa de pré-processamento de dados do pipeline utilizando um `ColumnTransformer` que nos permite especificar não só o nome e função de cada etapa do pipeline mas também quais variáveis são tratadas por cada etapa. Abaixo criamos o braço `NUMPREP` para lidar com variáveis numéricas e o braço `CATPREP` para lidar com variáveis categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep = ColumnTransformer(transformers=[('NUMPREP', num_pipeline, num_vars),\n",
    "                                           ('CATPREP', cat_pipeline, cat_vars)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fit = DecisionTreeRegressor()\n",
    "pipeline = Pipeline(steps=[('PRE', dataprep),\n",
    "                           ('MODEL', tree_fit)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'PRE__NUMPREP__PCA__n_components' : range(1, len(num_vars)),\n",
    "    'PRE__CATPREP__KB__k' : range(1, len(cat_vars)),\n",
    "    'MODEL__max_depth' : range(1, 150),\n",
    "    'MODEL__min_samples_split' : range(2, 40),\n",
    "    'MODEL__min_samples_leaf' : range(1, 20),\n",
    "}\n",
    "\n",
    "grid_fit = RandomizedSearchCV(pipeline, param_grid, cv = 5, n_iter = 5000)\n",
    "grid_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_train = mean_squared_error(y_train, grid_fit.predict(X_train))\n",
    "erro_test = mean_squared_error(y_test, grid_fit.predict(X_test))\n",
    "print(grid_fit.best_params_)\n",
    "print(f\"RMSE Train: {np.sqrt(erro_train)}\\nRMSE Test: {np.sqrt(erro_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando Pipelines com XGBoost\n",
    "\n",
    "Nas últimas aulas vimos que podemos ir além da SKLEARN e utilizar modelos de ponta dentro do Python através da biblioteca catboost. Atualmente, 3 algoritmos são dominantes em termos de capacidade preditiva: catboost, XGBoost e LightGBM. Vimos como utilizar o catboost para criar modelos de boosting robustos, utilizando o early stopping para impedir o overfitting.\n",
    "\n",
    "Hoje vamos utilizar a XGBoost através de sua biblioteca Python. Como esta biblioteca fornece uma interface compatível com a SKLEARN, poderemos incluir o `XGBRegressor` em nosso pipeline preditivo.\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos inicializar um novo pipeline com o XGBoost na etapa `MODEL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fit = xgb.XGBRegressor(n_jobs = -1)\n",
    "pipeline = Pipeline(steps=[('PRE', dataprep),\n",
    "                           ('MODEL', xgb_fit)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo XGBoost, assim como o catboost, é enorme e permite um altissimo grau de customização - permitindo a construção de modelos específicos para cada problema que precisarmos resolver. No entanto, essa flexibilidade tem um custo: complexidade. Primeiro, vamos lembrar que a complexidade de todo modelo de ensemble é ligada à dois fatores distintos: penalização de estimadores fracos individuais e penalizações gerais.\n",
    "\n",
    "Primeiro, vamos analisar 4 hiperparâmetros que controlam a complexidade do modelo ao longo desses dois eixos:\n",
    "* **max_depth**: profundidade máxima de cada estimador fraco **(penalização de estimador fraco)**. **QUANTO MAIOR, MAIS COMPLEXO, MAIS OVERFITTING**.\n",
    "* **min_child_weight**: um limite de pureza que o modelo busca em cada folha de cada árvore construída **(penalização de estimador fraco)**. **QUANTO MENOR, MAIS COMPLEXO, MAIS OVERFITTING**.\n",
    "* **gamma**: controla a complexidade de cada estimador com base na complexidade do modelo completo - conforme adicionamos árvores aumentamos o custo de novas árvores terem muitas folhas **(penalização geral)**. **QUANTO MENOR, MAIS COMPLEXO, MAIS OVERFITTING**.\n",
    "* **n_estimators**: o número de estimadores fracos que serão construídos **(penalização geral)**. **QUANTO MAIOR, MAIS COMPLEXO, MAIS OVERFITTING**.\n",
    "\n",
    "Além disso, o XGBoost realiza a construção de cada novo estimador sobre uma amostra dos dados completa. Podemos reduzir a chance de overfitting alterando 3 parâmetros chaves relativos a esse processo:\n",
    "\n",
    "\n",
    "* **eta**: taxa de aprendizagem, o quanto cada etapa de boosting pode contributir ao modelo. Idealmente queremos um eta baixo e um num_rounds alto, embora isso encorra em custos computacionais maiores. **QUANTO MAIOR, MAIS RÁPIDO, MAIS OVERFITTING**.\n",
    "* **subsample**: % da base completa de treinamento que o XGBoost utiliza para construir cada estimador fraco. **QUANTO MAIOR, MAIS RÁPIDO, MAIS OVERFITTING**.\n",
    "* **colsample_bytree**: % dos features que o XGBoost utilizará para construir cada estimador fraco. **QUANTO MAIOR, MAIS RÁPIDO, MAIS OVERFITTING**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'PRE__NUMPREP__PCA__n_components' : range(1, len(num_vars)),\n",
    "    'PRE__CATPREP__KB__k' : range(1, len(cat_vars)),\n",
    "    'MODEL__max_depth' : range(1, 10),\n",
    "    'MODEL__eta' : np.linspace(0.01, 1, 100), \n",
    "    \"MODEL__min_child_weight\": np.linspace(0.01, 5, 100),          \n",
    "    \"MODEL__gamma\": np.linspace(0.01, 5, 100),                     \n",
    "    \"MODEL__colsample_bytree\" : np.linspace(0.6, 0.9, 100),                \n",
    "    'MODEL__subsample':np.linspace(0.4, 0.8, 100),\n",
    "    'MODEL__n_estimators':[int(x) for x in np.linspace(5, 250, 100)],\n",
    "}\n",
    "\n",
    "grid_fit = RandomizedSearchCV(pipeline, param_grid, cv = 5, n_iter = 500)\n",
    "grid_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_train = mean_squared_error(y_train, grid_fit.predict(X_train))\n",
    "erro_test = mean_squared_error(y_test, grid_fit.predict(X_test))\n",
    "print(grid_fit.best_params_)\n",
    "print(f\"RMSE Train: {np.sqrt(erro_train)}\\nRMSE Test: {np.sqrt(erro_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "param = {\n",
    "    'eta': 0.10,                      # Lower ratios avoid over-fitting. Default is 3.\n",
    "    'max_depth': 30,                  # Lower ratios avoid over-fitting. Default is 6.\n",
    "    \"min_child_weight\": 3,            # Larger ratios avoid over-fitting. Default is 1.\n",
    "    \"gamma\": 0.3,                     # Larger values avoid over-fitting. Default is 0. \n",
    "    \"colsample_bytree\" : 0.7,         # Lower ratios avoid over-fitting. Values from 0.3 to 0.8 if you have many columns (especially if you did one-hot encoding), or 0.8 to 1 if you only have a few columns.\n",
    "    \"reg_lambda\": 10,                 # Larger ratios avoid over-fitting. Default is 1.\n",
    "    \"alpha\": 1,                       # Larger ratios avoid over-fitting. Default is 0.\n",
    "    'subsample':0.5,                  # Lower ratios avoid over-fitting. Default 1. 0.5 recommended.\n",
    "    'num_parallel_tree': 2,           # Parallel trees constructed during each iteration. Default is 1\n",
    "}\n",
    "\n",
    "testar com n_estimators de 200 à 600, especialmente para classificação\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "014f4a4a5af8f0104b12c029e500f4146d6d785e8cf714d2a35b7a9514230cd3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
